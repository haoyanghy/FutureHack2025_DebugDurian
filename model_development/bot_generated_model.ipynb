{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "762649ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dcedbbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1c52c3aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We stayed for a one night getaway with family ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Triple A rate with upgrade to view room was le...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This comes a little late as I'm finally catchi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Omni Chicago really delivers on all fronts...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I asked for a high floor away from the elevato...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  We stayed for a one night getaway with family ...      0\n",
       "1  Triple A rate with upgrade to view room was le...      0\n",
       "2  This comes a little late as I'm finally catchi...      0\n",
       "3  The Omni Chicago really delivers on all fronts...      0\n",
       "4  I asked for a high floor away from the elevato...      0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/processed_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "daeff2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "30ed62ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df[\"cleaned_text\"] = df[\"text\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b052e9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(1, 2), max_features=5000)\n",
    "tfidf_features = tfidf.fit_transform(df[\"cleaned_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "494b2786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "df[\"sentiment\"] = df[\"cleaned_text\"].apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45d91a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_exclamations(text):\n",
    "    return str(text).count(\"!\")\n",
    "\n",
    "df[\"exclamation_count\"] = df[\"text\"].apply(count_exclamations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712d5151",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([\n",
    "    pd.DataFrame(tfidf_features.toarray()),\n",
    "    df[[\"sentiment\", \"exclamation_count\"]],\n",
    "], axis=1)\n",
    "\n",
    "y = df[\"label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e08f1171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.84      4314\n",
      "           1       0.86      0.80      0.83      4293\n",
      "\n",
      "    accuracy                           0.84      8607\n",
      "   macro avg       0.84      0.84      0.84      8607\n",
      "weighted avg       0.84      0.84      0.84      8607\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(eval_metric='logloss')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0b961883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 Features:\n",
      "689: 0.0201\n",
      "1348: 0.0154\n",
      "4927: 0.0096\n",
      "3257: 0.0091\n",
      "4784: 0.0088\n",
      "4433: 0.0084\n",
      "111: 0.0076\n",
      "2088: 0.0072\n",
      "4849: 0.0069\n",
      "3124: 0.0064\n",
      "114: 0.0062\n",
      "2781: 0.0061\n",
      "500: 0.0061\n",
      "466: 0.0061\n",
      "28: 0.0061\n",
      "3575: 0.0060\n",
      "128: 0.0058\n",
      "4492: 0.0058\n",
      "2399: 0.0056\n",
      "921: 0.0056\n"
     ]
    }
   ],
   "source": [
    "if hasattr(model, 'feature_importances_'):\n",
    "    feature_importances = sorted(\n",
    "        zip(model.feature_importances_, X.columns), \n",
    "        reverse=True\n",
    "    )\n",
    "    print(\"\\nTop 20 Features:\")\n",
    "    for importance, feature in feature_importances[:20]:\n",
    "        print(f\"{feature}: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "03ac1375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(model, 'models/bot_detection_model.pkl')\n",
    "joblib.dump(tfidf, 'models/tfidf_vectorizer.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
